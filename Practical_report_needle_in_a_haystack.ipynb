{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARU-Bioinformatics/ARU-Bioinf-CMA-2021/blob/main/Practical_report_needle_in_a_haystack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "needed-princess",
      "metadata": {
        "id": "needed-princess"
      },
      "source": [
        "# Practical report - \"finding a needle in a haystack\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "impressive-today",
      "metadata": {
        "id": "impressive-today"
      },
      "source": [
        "*In this practical we are going to perform some basic data transformations on a flat file database, convert it into a BLAST database and use it in an experiment. We will benchmark our analyses to identify what is the most appropriate tool to use. This is real data, and the results will be usable in future experiments and may be publishable.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "republican-ending",
      "metadata": {
        "id": "republican-ending"
      },
      "source": [
        "### The problem:\n",
        "\n",
        "We have an *Arabidopsis thaliana* reporter line that contains two reporter gene constructs which have integrated in two different unknown locations. The first reporter gene they contain is a luciferase reporter called *CAB2:LUC+*, which consists of the promoter of the CAB2 gene fused to firefly luciferase. The second reporter they contain is the *35S:AEQ* construct, the strong 35S viral promoter driving expression of the AEQUORIN gene from jellyfish. Both of these genes make the plant glow in the dark.\n",
        "\n",
        "These plants have been used for many experiments, and the genome sequence of the Ws-2 ecotype has been published many times. However, we do not know the genomic locations of the reporter gene inserts. The gene for LUC and AEQ are on the end of each construct, and so should be neighbouring genomic DNA. We need to find out where the genes are integrated, and have some NGS reads from the line generated for a different experiment (Hearn et al., 2018).\n",
        "\n",
        "The reads are stored on the short read archive, and can be accessed here:\n",
        "https://www.ncbi.nlm.nih.gov/sra/SRX3230258\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Materials:\n",
        "\n",
        "The paired end reads on the [short read archive](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR6117531)\n",
        "\n",
        "The sequence of the [luciferase](https://github.com/ARU-Bioinformatics/ARU-Bioinf-CMA-2021/blob/main/firefly.fa) gene in fasta format\n",
        "\n",
        "The seuence of the [aequourin](https://github.com/ARU-Bioinformatics/ARU-Bioinf-CMA-2021/blob/main/AEQ_CDS.fa) gene in fasta format"
      ],
      "metadata": {
        "id": "YDYPI-vxvCve"
      },
      "id": "YDYPI-vxvCve"
    },
    {
      "cell_type": "markdown",
      "id": "worst-bench",
      "metadata": {
        "id": "worst-bench"
      },
      "source": [
        "### The solution:\n",
        "We need to convert the FASTQ file into something that can be searched against efficiently using an algorithm, such as BLAST. The most convenient file type to transform it to is FASTA. We therefore need to choose a way to transform our FASTQ data into FASTA data. Then we need to make a BLAST library from our sequence FASTA data and search it using the sequence of firefly luciferase and apoaequorin. Once we have a hit we will need to identify what region of the genome the additional sequence of the read aligns to. Finally, we will benchmark the time it takes to deploy our solution. Our final output should be an image of the genomic region our transgenes have inserted into."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "therapeutic-infrared",
      "metadata": {
        "id": "therapeutic-infrared"
      },
      "source": [
        "### The method:\n",
        "*You are free to deploy any method you like, the ideas here utilise mainly Unix commands. You are encourage to use Python where possible.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jClPYy8Qwlf_"
      },
      "source": [
        "**Step 1)** The first step is to bring into our environment the data we need from the links above. "
      ],
      "id": "jClPYy8Qwlf_"
    },
    {
      "cell_type": "code",
      "source": [
        "# your solution here"
      ],
      "metadata": {
        "id": "pVNgGjXEwm_H"
      },
      "id": "pVNgGjXEwm_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj6EjFaiwxtc"
      },
      "source": [
        "**Step 2)** Then we need to install any packages we need to do our analysis. For example, we might want to set up miniconda, and then install BLAST. "
      ],
      "id": "pj6EjFaiwxtc"
    },
    {
      "cell_type": "code",
      "source": [
        "# your solution here"
      ],
      "metadata": {
        "id": "N4N87RIaw8O6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "N4N87RIaw8O6"
    },
    {
      "cell_type": "markdown",
      "id": "creative-disaster",
      "metadata": {
        "id": "creative-disaster"
      },
      "source": [
        "**Step 3)** Choose a method for converting from fastq to fasta. Two different methods are presented here, <code>awk</code> and EMBOSS:seqret. You could also use <code>sed</code> or the fastx toolkit. Use one of these methods to begin with. It is always good to check whether a Unix command or a software tool developed specifically for bioinformatics is best for what we want to achieve. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ideal-jurisdiction",
      "metadata": {
        "id": "ideal-jurisdiction"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat ~/FASTQ_data/32.fastqsanger | awk '{if(NR%4==1) {printf(\">%s\\n\",substr($0,2));} else if(NR%4==2) print;}' > 32.fasta\n",
        "head 32.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiovascular-skiing",
      "metadata": {
        "id": "cardiovascular-skiing"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "seqret -sequence ~/FASTQ_data/32.fastqsanger -outseq 32.fasta\n",
        "head 32.fasta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "liable-sailing",
      "metadata": {
        "id": "liable-sailing"
      },
      "source": [
        "We can benchmark a process in terms of the time it takes to run. For dealing with very large FASTQ and FASTA files this is very important to do. I benchmark using the <code>perf stat</code> command. Replace the text in pointy brackets with whatever tool above you preferred. You may have a favoured alternative e.g. <code>time</code>, so please substitute as you see fit. To make running <code>perf stat</code> easier I have placed the fastq to fasta line inside a bash script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "broken-disorder",
      "metadata": {
        "scrolled": true,
        "id": "broken-disorder"
      },
      "outputs": [],
      "source": [
        "%%writefile awk_fastq.sh\n",
        "#!/bin/bash\n",
        "cat ~/FASTQ_data/32.fastqsanger | awk '{if(NR%4==1) {printf(\">%s\\n\",substr($0,2));} else if(NR%4==2) print;}' > 32.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clean-drove",
      "metadata": {
        "scrolled": true,
        "id": "clean-drove"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "sudo perf stat -r 10 -d --table -o seqret_perf.txt bash ./awk_fastq.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "revised-knock",
      "metadata": {
        "id": "revised-knock"
      },
      "source": [
        "**Step 4)** Make a blast library. magicblast has a command to make a blast database <code>makeblastdb</code>. Magic-blast and BLAST are not pre-installed on this VM, so you will have to identofy how to install them. Note that some older information on the internet will recommend using the EMBOSS formatdb package. Please do not use this. There is a good overview here: https://www.ncbi.nlm.nih.gov/books/NBK569841/. Detailed instructions for using <code>makeblastdb</code> are available here: https://ncbi.github.io/magicblast/cook/blastdb.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "magnetic-placement",
      "metadata": {
        "id": "magnetic-placement"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "makeblastdb -in 32.fasta -dbtype nucl -out 32_database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "federal-investing",
      "metadata": {
        "id": "federal-investing"
      },
      "source": [
        "For this command we specify the following arguments:\n",
        "        <code>-in </code>\n",
        "        <code>-dbtype</code>\n",
        "        <code>-out</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intended-surveillance",
      "metadata": {
        "id": "intended-surveillance"
      },
      "source": [
        "**Step 5)** When you have configured a BLAST library it is time to run <code>blastn</code> using one of the query sequences in the FASTA query folder. The overview in the BLAST+ user manual is useful to read before beginning: https://www.ncbi.nlm.nih.gov/books/NBK569856/. There are four query sequences in the FASTA_query directory - choose one of these to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprising-commercial",
      "metadata": {
        "id": "surprising-commercial"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd FASTA_queries \n",
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wicked-perspective",
      "metadata": {
        "id": "wicked-perspective"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "blastn -db 32_database -query ~/FASTA_queries/firefly.fa -out results_db.out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "elect-shoot",
      "metadata": {
        "id": "elect-shoot"
      },
      "source": [
        "For this command we specify the following arguments:\n",
        "        <code>-db </code>\n",
        "        <code>-query</code>\n",
        "        <code>-out</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "capable-distributor",
      "metadata": {
        "id": "capable-distributor"
      },
      "source": [
        "**STOP!** Why did we need to make a database for BLAST to run? BLAST will accepy a plain flat file fasta as input -try it out and see. Instead of specifying the <code>-db</code> argument use <code>-subject</code> instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "horizontal-shelter",
      "metadata": {
        "id": "horizontal-shelter"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "blastn -subject 32.fasta -query ~/FASTA_queries/firefly.fa -out results_fas.out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "medium-configuration",
      "metadata": {
        "id": "medium-configuration"
      },
      "source": [
        "Let's identify the main reason why we need to make the blast database and index. Compare the performance of using <code>-db</code> over <code>-subject</code> with the <code>perf stat</code> command. The various arguments for <code>blastn</code> confuse <code>perf stat</code> so I have placed them in single line bash scripts again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "numerous-commissioner",
      "metadata": {
        "scrolled": true,
        "id": "numerous-commissioner"
      },
      "outputs": [],
      "source": [
        "%%writefile blast_fas.sh\n",
        "#!/bin/bash\n",
        "/anaconda/envs/py37_default/bin/blastn -subject 32.fasta -query ~/FASTA_queries/firefly.fa -out results_fas.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loose-testament",
      "metadata": {
        "scrolled": true,
        "id": "loose-testament"
      },
      "outputs": [],
      "source": [
        "%%writefile blast_db.sh\n",
        "#!/bin/bash\n",
        "/anaconda/envs/py37_default/bin/blastn -db 32_database -query ~/FASTA_queries/firefly.fa -out results_db.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "major-nancy",
      "metadata": {
        "scrolled": true,
        "id": "major-nancy"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "sudo perf stat -r 10 -d --table -o time_fs.txt bash ./blast_fas.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moving-optimum",
      "metadata": {
        "scrolled": true,
        "id": "moving-optimum"
      },
      "outputs": [],
      "source": [
        "%%!\n",
        "sudo perf stat -r 10 -d --table -o time_db.txt bash ./blast_db.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thrown-combining",
      "metadata": {
        "id": "thrown-combining"
      },
      "source": [
        "**Step 6)** Over to you! The final step is to use the reads identified to identify where the trans genes have inserted themselves. This is a slightly more involved process. You will need to clip the seqeunce to remove the region that aligns to the trasngenes, and then compare this against the reference seqeunce (e.g. using BLAST). This will tell you where your sequence has inserted.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Practical report - needle in a haystack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}